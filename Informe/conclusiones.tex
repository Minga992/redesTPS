\section{Conclusiones}

Este fenómeno de que la mayoría de símbolos provean una cantidad información muy por encima de la entropía y sólo unos pocos por debajo, se presenta en todas las capturas. Si la entropía es una medida que indica la cantidad media de información por símbolo, ¿cómo se explica que tantos símbolos se encuentren muy por sobre la media y tan sólo una minoría por debajo? Esto puede explicarse dando un vistazo a las probabilidades de cada símbolo. Se puede ver en los resultados de las capturas que los símbolos que proveen la menor cantidad de información son aquellos con las probabilidades más altas y esto se condice con la teoría de la información, es decir, los sucesos con las probabilidades de ocurrencia más altas son los que aportan menos información (y viceversa), y a su vez si un suceso tiene 100\% de probabilidad de ocurrencia entonces se dice que su cantidad de información es $cero$. La entropía está directamente relacionada con la capacidad de distinguir símbolos, es decir, cuando la entropía es máxima todos los símbolos proveen la misma cantidad de información y son equiprobables, no hay ninguno que se distinga, y en cambio cuando los símbolos no son equiprobables y la entropía es baja se pueden distinguir aquellos símbolos que provean la menor cantidad de información, o sea, los que tengan las probabilidades más altas.
 Por otro lado, y de manera curiosa, las redes más grandes presentaron muchas similutudes en los experimentos, (sobre todo el primero y el último), mientras que la red más chica (el Cyber), se distinguía de ámbos en todo aspecto(por ejemplo, información de paquetes broadcast o el hecho de que inclusive la fuente Origen generaba símbolos distinguidos).
 Para terminar, en cuanto a la pregunta que nos hicimos al principio del proyecto sobre que fuente elegir, si aquella que representaba los destinos, o la de los orígenes, los experimentos sostuvieron que la fuente que más símbolos distinguía era la de destino, probablemente por los gateaway de las redes.