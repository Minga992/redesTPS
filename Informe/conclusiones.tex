\section{Conclusiones}

Este fenómeno de que la mayoría de símbolos provean una cantidad información muy por encima de la entropía y sólo unos pocos por debajo, se presenta en todas las capturas. Si la entropía es una medida que indica la cantidad media de información por símbolo, ¿cómo se explica que tantos símbolos se encuentren muy por sobre la media y tan sólo una minoría por debajo? Esto puede explicarse dando un vistazo a las probabilidades de cada símbolo. Se puede ver en los resultados de las capturas que los símbolos que proveen la menor cantidad de información son aquellos con las probabilidades más altas y esto se condice con la teoría de la información, es decir, los sucesos con las probabilidades de ocurrencia más altas son los que aportan menos información (y viceversa), y a su vez si un suceso tiene 100\% de probabilidad de ocurrencia entonces se dice que su cantidad de información es $cero$.